{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05909f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import requests\n",
    "import datetime\n",
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5fadd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>stock</th>\n",
       "      <th>Bearish</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Bullish</th>\n",
       "      <th>Total_Compound</th>\n",
       "      <th>Date</th>\n",
       "      <th>high52</th>\n",
       "      <th>low52</th>\n",
       "      <th>returnOnEquity</th>\n",
       "      <th>returnOnAssets</th>\n",
       "      <th>totalDebtToCapital</th>\n",
       "      <th>totalDebtToEquity</th>\n",
       "      <th>vol10DayAvg</th>\n",
       "      <th>pegRatio</th>\n",
       "      <th>marketCap</th>\n",
       "      <th>dividendYield</th>\n",
       "      <th>epsTTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.146714</td>\n",
       "      <td>0.692571</td>\n",
       "      <td>0.160679</td>\n",
       "      <td>-0.065818</td>\n",
       "      <td>1645506000</td>\n",
       "      <td>1243.4900</td>\n",
       "      <td>546.9800</td>\n",
       "      <td>21.07834</td>\n",
       "      <td>9.87758</td>\n",
       "      <td>17.78900</td>\n",
       "      <td>22.63738</td>\n",
       "      <td>24059852.0</td>\n",
       "      <td>0.307284</td>\n",
       "      <td>1080801.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.92162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DKNG</td>\n",
       "      <td>0.035870</td>\n",
       "      <td>0.779870</td>\n",
       "      <td>0.184217</td>\n",
       "      <td>0.495400</td>\n",
       "      <td>1645506000</td>\n",
       "      <td>64.6000</td>\n",
       "      <td>14.9700</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>42.65325</td>\n",
       "      <td>74.37779</td>\n",
       "      <td>19558468.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7225.412</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FB</td>\n",
       "      <td>0.130636</td>\n",
       "      <td>0.692909</td>\n",
       "      <td>0.176364</td>\n",
       "      <td>0.093436</td>\n",
       "      <td>1645506000</td>\n",
       "      <td>384.3300</td>\n",
       "      <td>185.8200</td>\n",
       "      <td>31.10175</td>\n",
       "      <td>24.20513</td>\n",
       "      <td>0.46310</td>\n",
       "      <td>0.46525</td>\n",
       "      <td>28533150.0</td>\n",
       "      <td>0.441493</td>\n",
       "      <td>607809.600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.78663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DWAC</td>\n",
       "      <td>0.147533</td>\n",
       "      <td>0.752067</td>\n",
       "      <td>0.100267</td>\n",
       "      <td>-0.025420</td>\n",
       "      <td>1645506000</td>\n",
       "      <td>175.0000</td>\n",
       "      <td>9.8401</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2665709.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1767.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AMD</td>\n",
       "      <td>0.034583</td>\n",
       "      <td>0.669250</td>\n",
       "      <td>0.296333</td>\n",
       "      <td>0.491358</td>\n",
       "      <td>1645506000</td>\n",
       "      <td>164.4599</td>\n",
       "      <td>72.5000</td>\n",
       "      <td>47.42763</td>\n",
       "      <td>29.52154</td>\n",
       "      <td>4.00768</td>\n",
       "      <td>4.17500</td>\n",
       "      <td>103828029.0</td>\n",
       "      <td>1.540659</td>\n",
       "      <td>167961.800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.57396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>185</td>\n",
       "      <td>AMD</td>\n",
       "      <td>0.114756</td>\n",
       "      <td>0.707111</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.106509</td>\n",
       "      <td>1648699200</td>\n",
       "      <td>164.4599</td>\n",
       "      <td>72.5000</td>\n",
       "      <td>47.42763</td>\n",
       "      <td>29.52154</td>\n",
       "      <td>4.00768</td>\n",
       "      <td>4.17500</td>\n",
       "      <td>103828029.0</td>\n",
       "      <td>1.540659</td>\n",
       "      <td>167961.800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.57396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>186</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.089564</td>\n",
       "      <td>0.774218</td>\n",
       "      <td>0.136200</td>\n",
       "      <td>0.115873</td>\n",
       "      <td>1648699200</td>\n",
       "      <td>1243.4900</td>\n",
       "      <td>546.9800</td>\n",
       "      <td>21.07834</td>\n",
       "      <td>9.87758</td>\n",
       "      <td>17.78900</td>\n",
       "      <td>22.63738</td>\n",
       "      <td>24059852.0</td>\n",
       "      <td>0.307284</td>\n",
       "      <td>1080801.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.92162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>187</td>\n",
       "      <td>TLRY</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.671821</td>\n",
       "      <td>0.196214</td>\n",
       "      <td>0.099411</td>\n",
       "      <td>1648699200</td>\n",
       "      <td>23.0400</td>\n",
       "      <td>4.7800</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>13.21841</td>\n",
       "      <td>15.34299</td>\n",
       "      <td>103438612.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3485.251</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>188</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>0.719833</td>\n",
       "      <td>0.189722</td>\n",
       "      <td>0.296533</td>\n",
       "      <td>1648699200</td>\n",
       "      <td>346.4700</td>\n",
       "      <td>134.5900</td>\n",
       "      <td>44.83623</td>\n",
       "      <td>26.72860</td>\n",
       "      <td>29.14426</td>\n",
       "      <td>41.13182</td>\n",
       "      <td>54131912.0</td>\n",
       "      <td>0.514619</td>\n",
       "      <td>612615.700</td>\n",
       "      <td>0.07</td>\n",
       "      <td>3.84519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>189</td>\n",
       "      <td>SNDL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.970444</td>\n",
       "      <td>0.029556</td>\n",
       "      <td>0.049322</td>\n",
       "      <td>1648699200</td>\n",
       "      <td>1.4900</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.78199</td>\n",
       "      <td>1.81432</td>\n",
       "      <td>236207985.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1494.236</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 stock   Bearish   Neutral   Bullish  Total_Compound  \\\n",
       "0             0  TSLA  0.146714  0.692571  0.160679       -0.065818   \n",
       "1             1  DKNG  0.035870  0.779870  0.184217        0.495400   \n",
       "2             2    FB  0.130636  0.692909  0.176364        0.093436   \n",
       "3             3  DWAC  0.147533  0.752067  0.100267       -0.025420   \n",
       "4             4   AMD  0.034583  0.669250  0.296333        0.491358   \n",
       "..          ...   ...       ...       ...       ...             ...   \n",
       "185         185   AMD  0.114756  0.707111  0.178100        0.106509   \n",
       "186         186  TSLA  0.089564  0.774218  0.136200        0.115873   \n",
       "187         187  TLRY  0.132000  0.671821  0.196214        0.099411   \n",
       "188         188  NVDA  0.090500  0.719833  0.189722        0.296533   \n",
       "189         189  SNDL  0.000000  0.970444  0.029556        0.049322   \n",
       "\n",
       "           Date     high52     low52  returnOnEquity  returnOnAssets  \\\n",
       "0    1645506000  1243.4900  546.9800        21.07834         9.87758   \n",
       "1    1645506000    64.6000   14.9700         0.00000         0.00000   \n",
       "2    1645506000   384.3300  185.8200        31.10175        24.20513   \n",
       "3    1645506000   175.0000    9.8401         0.00000         0.00000   \n",
       "4    1645506000   164.4599   72.5000        47.42763        29.52154   \n",
       "..          ...        ...       ...             ...             ...   \n",
       "185  1648699200   164.4599   72.5000        47.42763        29.52154   \n",
       "186  1648699200  1243.4900  546.9800        21.07834         9.87758   \n",
       "187  1648699200    23.0400    4.7800         0.00000         0.00000   \n",
       "188  1648699200   346.4700  134.5900        44.83623        26.72860   \n",
       "189  1648699200     1.4900    0.4000         0.00000         0.00000   \n",
       "\n",
       "     totalDebtToCapital  totalDebtToEquity  vol10DayAvg  pegRatio  \\\n",
       "0              17.78900           22.63738   24059852.0  0.307284   \n",
       "1              42.65325           74.37779   19558468.0  0.000000   \n",
       "2               0.46310            0.46525   28533150.0  0.441493   \n",
       "3               0.00000            0.00000    2665709.0  0.000000   \n",
       "4               4.00768            4.17500  103828029.0  1.540659   \n",
       "..                  ...                ...          ...       ...   \n",
       "185             4.00768            4.17500  103828029.0  1.540659   \n",
       "186            17.78900           22.63738   24059852.0  0.307284   \n",
       "187            13.21841           15.34299  103438612.0  0.000000   \n",
       "188            29.14426           41.13182   54131912.0  0.514619   \n",
       "189             1.78199            1.81432  236207985.0  0.000000   \n",
       "\n",
       "       marketCap  dividendYield    epsTTM  \n",
       "0    1080801.000           0.00   4.92162  \n",
       "1       7225.412           0.00   0.00000  \n",
       "2     607809.600           0.00  13.78663  \n",
       "3       1767.700           0.00   0.00000  \n",
       "4     167961.800           0.00   2.57396  \n",
       "..           ...            ...       ...  \n",
       "185   167961.800           0.00   2.57396  \n",
       "186  1080801.000           0.00   4.92162  \n",
       "187     3485.251           0.00   0.00000  \n",
       "188   612615.700           0.07   3.84519  \n",
       "189     1494.236           0.00   0.00000  \n",
       "\n",
       "[190 rows x 18 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.read_csv('df_merged.csv')\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3140643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_merged_df(df_merged):\n",
    "    \n",
    "#     saturday_rows=[]\n",
    "    \n",
    "#     x = list(df_merged[\"Date\"])\n",
    "#     counter1=0 #Count of row in data_frame\n",
    "#     for date in df:\n",
    "#         dotw = ((date//86400)+4)%7\n",
    "#         if (dotw==0):\n",
    "#             saturday_rows.append(df_merged.index[counter1])\n",
    "#         counter1+=1\n",
    "    \n",
    "#     df_merged_new = df_merged.drop(saturday_rows)\n",
    "#     return df_merged_new\n",
    "            \n",
    "# #     check if all the columns were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f947af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting rid of satur-days\n",
    "\n",
    "df_merged.drop(df_merged.index[(((df_merged['Date'] //86400)+4)%7)==6], inplace=True)\n",
    "df_merged=df_merged.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84227f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Loading and cleaning df_merged\n",
    "\n",
    "# df_merged = pd.read_csv('df_merged.csv')\n",
    "# df_merged = clean_merged_df(df_merged)\n",
    "# df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a840c86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TSLA',\n",
       " 'DKNG',\n",
       " 'FB',\n",
       " 'DWAC',\n",
       " 'AMD',\n",
       " 'TSLA',\n",
       " 'FB',\n",
       " 'SP',\n",
       " 'AMD',\n",
       " 'CLOV',\n",
       " 'TSLA',\n",
       " 'FB',\n",
       " 'AMD',\n",
       " 'COIN',\n",
       " 'TA',\n",
       " 'TSLA',\n",
       " 'AMD',\n",
       " 'NVDA',\n",
       " 'FB',\n",
       " 'WISH',\n",
       " 'CLOV',\n",
       " 'SP',\n",
       " 'MAR',\n",
       " 'TSLA',\n",
       " 'FB',\n",
       " 'TSLA',\n",
       " 'LCID',\n",
       " 'ZM',\n",
       " 'SOFI',\n",
       " 'MSFT',\n",
       " 'SOFI',\n",
       " 'TSLA',\n",
       " 'INTC',\n",
       " 'AMD',\n",
       " 'FB',\n",
       " 'TSLA',\n",
       " 'SOFI',\n",
       " 'AMD',\n",
       " 'FB',\n",
       " 'AAPL',\n",
       " 'TSLA',\n",
       " 'COST',\n",
       " 'AMD',\n",
       " 'SOFI',\n",
       " 'SP',\n",
       " 'TSLA',\n",
       " 'CDEV',\n",
       " 'AMD',\n",
       " 'HOOD',\n",
       " 'SOFI',\n",
       " 'BBBY',\n",
       " 'TSLA',\n",
       " 'MU',\n",
       " 'AMD',\n",
       " 'AAPL',\n",
       " 'BBBY',\n",
       " 'TSLA',\n",
       " 'SP',\n",
       " 'NVDA',\n",
       " 'FB',\n",
       " 'TSLA',\n",
       " 'CLOV',\n",
       " 'AAPL',\n",
       " 'BBBY',\n",
       " 'AMD',\n",
       " 'AMZN',\n",
       " 'BBBY',\n",
       " 'TSLA',\n",
       " 'SP',\n",
       " 'DKNG',\n",
       " 'RIVN',\n",
       " 'AMZN',\n",
       " 'TSLA',\n",
       " 'DOCU',\n",
       " 'CLOV',\n",
       " 'TSLA',\n",
       " 'RIVN',\n",
       " 'AMD',\n",
       " 'AAPL',\n",
       " 'SOFI',\n",
       " 'TSLA',\n",
       " 'SOFI',\n",
       " 'AAPL',\n",
       " 'SP',\n",
       " 'RIVN',\n",
       " 'TSLA',\n",
       " 'SP',\n",
       " 'AAPL',\n",
       " 'SOFI',\n",
       " 'FB',\n",
       " 'TSLA',\n",
       " 'ME',\n",
       " 'SP',\n",
       " 'HYMC',\n",
       " 'NVDA',\n",
       " 'TSLA',\n",
       " 'SOFI',\n",
       " 'ME',\n",
       " 'AMZN',\n",
       " 'SP',\n",
       " 'TSLA',\n",
       " 'AMZN',\n",
       " 'AMD',\n",
       " 'TA',\n",
       " 'NVDA',\n",
       " 'TSLA',\n",
       " 'AMD',\n",
       " 'NVDA',\n",
       " 'FB',\n",
       " 'AAPL',\n",
       " 'MULN',\n",
       " 'CTXR',\n",
       " 'BBIG',\n",
       " 'TSLA',\n",
       " 'NVDA',\n",
       " 'TSLA',\n",
       " 'NVDA',\n",
       " 'FB',\n",
       " 'AMD',\n",
       " 'AMZN',\n",
       " 'TSLA',\n",
       " 'AMD',\n",
       " 'SIMO',\n",
       " 'TA',\n",
       " 'NVDA',\n",
       " 'TSLA',\n",
       " 'AAPL',\n",
       " 'NVDA',\n",
       " 'AMD',\n",
       " 'IBKR',\n",
       " 'TLRY',\n",
       " 'NVDA',\n",
       " 'TSLA',\n",
       " 'AMD',\n",
       " 'AAPL',\n",
       " 'TLRY',\n",
       " 'TSLA',\n",
       " 'NVDA',\n",
       " 'FB',\n",
       " 'SNDL',\n",
       " 'TLRY',\n",
       " 'FB',\n",
       " 'SNDL',\n",
       " 'AAPL',\n",
       " 'TSLA',\n",
       " 'TSLA',\n",
       " 'TLRY',\n",
       " 'AMD',\n",
       " 'AAPL',\n",
       " 'NVDA',\n",
       " 'TLRY',\n",
       " 'TSLA',\n",
       " 'MU',\n",
       " 'AAPL',\n",
       " 'BBBY',\n",
       " 'TLRY',\n",
       " 'TSLA',\n",
       " 'AMD',\n",
       " 'AAPL',\n",
       " 'NVDA',\n",
       " 'AMD',\n",
       " 'TSLA',\n",
       " 'TLRY',\n",
       " 'NVDA',\n",
       " 'SNDL']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Producing the stock list\n",
    "\n",
    "STOCKS = list(df_merged['stock'])\n",
    "\n",
    "#Producing the date list\n",
    "\n",
    "DATE = list(df_merged['Date'])\n",
    "\n",
    "#Initiallizing the price_df\n",
    "bad_api_calls = []\n",
    "price_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "STOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74b81bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TSLA',\n",
       " 'DKNG',\n",
       " 'FB',\n",
       " 'DWAC',\n",
       " 'AMD',\n",
       " 'TSLA',\n",
       " 'FB',\n",
       " 'SP',\n",
       " 'AMD',\n",
       " 'CLOV',\n",
       " 'TSLA',\n",
       " 'FB',\n",
       " 'AMD',\n",
       " 'COIN',\n",
       " 'TA',\n",
       " 'TSLA',\n",
       " 'AMD',\n",
       " 'NVDA',\n",
       " 'FB',\n",
       " 'WISH',\n",
       " 'CLOV',\n",
       " 'SP',\n",
       " 'MAR',\n",
       " 'TSLA',\n",
       " 'FB',\n",
       " 'TSLA',\n",
       " 'LCID',\n",
       " 'ZM',\n",
       " 'SOFI',\n",
       " 'MSFT',\n",
       " 'SOFI',\n",
       " 'TSLA',\n",
       " 'INTC',\n",
       " 'AMD',\n",
       " 'FB',\n",
       " 'TSLA',\n",
       " 'SOFI',\n",
       " 'AMD',\n",
       " 'FB',\n",
       " 'AAPL',\n",
       " 'TSLA',\n",
       " 'COST',\n",
       " 'AMD',\n",
       " 'SOFI',\n",
       " 'SP',\n",
       " 'TSLA',\n",
       " 'CDEV',\n",
       " 'AMD',\n",
       " 'HOOD',\n",
       " 'SOFI',\n",
       " 'BBBY',\n",
       " 'TSLA',\n",
       " 'MU',\n",
       " 'AMD',\n",
       " 'AAPL',\n",
       " 'BBBY',\n",
       " 'TSLA',\n",
       " 'SP',\n",
       " 'NVDA',\n",
       " 'FB',\n",
       " 'TSLA',\n",
       " 'CLOV',\n",
       " 'AAPL',\n",
       " 'BBBY',\n",
       " 'AMD',\n",
       " 'AMZN',\n",
       " 'BBBY',\n",
       " 'TSLA',\n",
       " 'SP',\n",
       " 'DKNG',\n",
       " 'RIVN',\n",
       " 'AMZN',\n",
       " 'TSLA',\n",
       " 'DOCU',\n",
       " 'CLOV',\n",
       " 'TSLA',\n",
       " 'RIVN',\n",
       " 'AMD',\n",
       " 'AAPL',\n",
       " 'SOFI',\n",
       " 'TSLA',\n",
       " 'SOFI',\n",
       " 'AAPL',\n",
       " 'SP',\n",
       " 'RIVN',\n",
       " 'TSLA',\n",
       " 'SP',\n",
       " 'AAPL',\n",
       " 'SOFI',\n",
       " 'FB',\n",
       " 'TSLA',\n",
       " 'ME',\n",
       " 'SP',\n",
       " 'HYMC',\n",
       " 'NVDA',\n",
       " 'TSLA',\n",
       " 'SOFI',\n",
       " 'ME',\n",
       " 'AMZN',\n",
       " 'SP',\n",
       " 'TSLA',\n",
       " 'AMZN',\n",
       " 'AMD',\n",
       " 'TA',\n",
       " 'NVDA',\n",
       " 'TSLA',\n",
       " 'AMD',\n",
       " 'NVDA',\n",
       " 'FB',\n",
       " 'AAPL',\n",
       " 'MULN',\n",
       " 'CTXR',\n",
       " 'BBIG',\n",
       " 'TSLA',\n",
       " 'NVDA',\n",
       " 'TSLA',\n",
       " 'NVDA',\n",
       " 'FB',\n",
       " 'AMD',\n",
       " 'AMZN',\n",
       " 'TSLA',\n",
       " 'AMD',\n",
       " 'SIMO',\n",
       " 'TA',\n",
       " 'NVDA',\n",
       " 'TSLA',\n",
       " 'AAPL',\n",
       " 'NVDA',\n",
       " 'AMD',\n",
       " 'IBKR',\n",
       " 'TLRY',\n",
       " 'NVDA',\n",
       " 'TSLA',\n",
       " 'AMD',\n",
       " 'AAPL',\n",
       " 'TLRY',\n",
       " 'TSLA',\n",
       " 'NVDA',\n",
       " 'FB',\n",
       " 'SNDL',\n",
       " 'TLRY',\n",
       " 'FB',\n",
       " 'SNDL',\n",
       " 'AAPL',\n",
       " 'TSLA',\n",
       " 'TSLA',\n",
       " 'TLRY',\n",
       " 'AMD',\n",
       " 'AAPL',\n",
       " 'NVDA',\n",
       " 'TLRY',\n",
       " 'TSLA',\n",
       " 'MU',\n",
       " 'AAPL',\n",
       " 'BBBY',\n",
       " 'TLRY',\n",
       " 'TSLA',\n",
       " 'AMD',\n",
       " 'AAPL',\n",
       " 'NVDA',\n",
       " 'AMD',\n",
       " 'TSLA',\n",
       " 'TLRY',\n",
       " 'NVDA',\n",
       " 'SNDL']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "940b1383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Junk to get row\n",
    "\n",
    "# api_call = get_daily_adjusted_price_data('GME')\n",
    "# api_call = json_normalize(api_call)\n",
    "# # dataframe = create_dataframe(api_call)\n",
    "# # dataframe\n",
    "# api_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b26840ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'candles': [], 'symbol': 'FB', 'empty': True}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # #Junk\n",
    "\n",
    "# define an endpoint with a stock of your choice, MUST BE UPPER\n",
    "endpoint = r\"https://api.tdameritrade.com/v1/marketdata/{}/pricehistory\".format('FB')\n",
    "\n",
    "# define the payload\n",
    "payload = {'apikey':'4JHA7B4AE8VS1DQDUGATGHZPQIZNODEO',\n",
    "           'periodType':'day',\n",
    "           'frequencyType':'minute',\n",
    "           'frequency':'1',\n",
    "           'period':'2',\n",
    "           'endDate':'1556158524000',\n",
    "           'startDate':'1554535854000',\n",
    "           'needExtendedHoursData':'true'}\n",
    "\n",
    "# make a request\n",
    "content = requests.get(url = endpoint, params = payload)\n",
    "\n",
    "print(content)\n",
    "\n",
    "# convert it dictionary object\n",
    "data = content.json()\n",
    "\n",
    "# payload_price = {'apikey': '4JHA7B4AE8VS1DQDUGATGHZPQIZNODEO',\n",
    "#                            'periodType' : 'day',\n",
    "#                            'period':'1',\n",
    "#                            'frequencyType':'daily',\n",
    "#                            'frequency':'daily',\n",
    "#                                'endDate':{DATE[0]+86400},\n",
    "#                                'startDate' : {DATE[0]},\n",
    "#                                'needExtendedHoursData' : 'false'\n",
    "#                           }\n",
    "# api_call = json_normalize(api_call)\n",
    "\n",
    "data\n",
    "\n",
    "# if len(api_call['c']) == 1:\n",
    "#     api_call['c']=api_call['c'][0]\n",
    "# else:\n",
    "#     api_call['c']=api_call['c'][0][0]\n",
    "            \n",
    "# if len(api_call['o']) == 1:\n",
    "#     api_call['o'] = api_call['o'][0]\n",
    "# else:\n",
    "#     api_call['o']=api_call['o'][0][0]\n",
    "\n",
    "# if len(api_call['h']) == 1:\n",
    "#     api_call['h'] = api_call['h'][0]\n",
    "# else:\n",
    "#     api_call['h']=api_call['h'][0][0]\n",
    "\n",
    "# api_call\n",
    "# #api_call['o']=api_call['o'][0][0]\n",
    "# api_call['return'] = api_call['o'] - api_call['c']\n",
    "# if (api_call['return'][0]) > 0:\n",
    "#     api_call['direction'] = 2\n",
    "# else:\n",
    "#     api_call['direction'] = 1\n",
    "\n",
    "# api_call['stock'] = 'GME'\n",
    "\n",
    "# # api_call = api_call.drop(columns=['t', 'v', 's', 'l'],axis=1)\n",
    "# api_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cc0a5192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get price and price direction\n",
    "\n",
    "def create_price_direction_df(stocks,start):\n",
    "    #CAUTION REMEMBER TO FIX THE START DATE AND END DATE\n",
    "    df=pd.DataFrame([])\n",
    "    count=0\n",
    "    counter_=1\n",
    "    for stock in stocks:\n",
    "        print(count)\n",
    "        endpoint = f\"https://api.tdameritrade.com/v1/marketdata/{stock}/pricehistory\"\n",
    "        payload_price = {'apikey': '4JHA7B4AE8VS1DQDUGATGHZPQIZNODEO',\n",
    "                           'periodType' : 'day',\n",
    "                           'period':'1',\n",
    "                           'frequencyType':'daily',\n",
    "                           'frequency':'daily',\n",
    "                               'endDate':{start[count]+86400},\n",
    "                               'startDate' : {start[count]},\n",
    "                               'needExtendedHoursData' : 'false'\n",
    "                          }\n",
    "        \n",
    "        pricing_content = requests.get(url = endpoint, params=payload_price).json()\n",
    "        df_temp=pd.DataFrame.from_dict(pricing_content, orient = 'index')\n",
    "        df = pd.concat([df,df_temp])\n",
    "        count+=1\n",
    "        \n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "64fd699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "error  Bad request.\n",
       "error  Bad request.\n",
       "error  Bad request.\n",
       "error  Bad request.\n",
       "error  Bad request.\n",
       "...             ...\n",
       "error  Bad request.\n",
       "error  Bad request.\n",
       "error  Bad request.\n",
       "error  Bad request.\n",
       "error  Bad request.\n",
       "\n",
       "[190 rows x 1 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df = create_price_direction_df(STOCKS,DATE)\n",
    "price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0c386171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>Bad request.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "error  Bad request.\n",
       "error  Bad request.\n",
       "error  Bad request.\n",
       "error  Bad request.\n",
       "error  Bad request.\n",
       "...             ...\n",
       "error  Bad request.\n",
       "error  Bad request.\n",
       "error  Bad request.\n",
       "error  Bad request.\n",
       "error  Bad request.\n",
       "\n",
       "[190 rows x 1 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d1303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = price_df.reset_index()#temp this CAUTION\n",
    "price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0560ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the sentiment analysis and price_df and clean\n",
    "df_merged = pd.concat([df_merged,price_df], axis=1)\n",
    "\n",
    "#Renaming columns\n",
    "df_merged = df_merged.rename(columns={'c':'closing_price', 'h':'highest_price', 'o':'opeing_price'})\n",
    "\n",
    "#Remove duplicated columns\n",
    "df_final = df_merged.loc[:,~df_merged.columns.duplicated()]\n",
    "df_final\n",
    "#Figure how to incorporate specific periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac1abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further cleaning of the final data set\n",
    "\n",
    "# pd.options.mode.chained_assignment = None  # default='warn' disables warnings.\n",
    "\n",
    "# #convert to numeric data-type\n",
    "\n",
    "# int_list = ['bidSize', 'askSize', 'lastSize', 'totalVolume', 'regularMarketLastSize']\n",
    "# for int_ in int_list:\n",
    "#     df_final[int_] = pd.to_numeric(df_final[int_])\n",
    "# df_final['direction'] = pd.to_numeric(df_final['direction'])\n",
    "\n",
    "# # Columns should be integer data types\n",
    "# df_final['sharesOutstanding'] = pd.to_numeric(df_final['sharesOutstanding'])\n",
    "# df_final['vol1DayAvg'] = pd.to_numeric(df_final['vol1DayAvg'])\n",
    "# df_final['vol10DayAvg'] = pd.to_numeric(df_final['vol10DayAvg'])\n",
    "# df_final['vol3MonthAvg'] = pd.to_numeric(df_final['vol3MonthAvg'])\n",
    "\n",
    "\n",
    "# df_final.rename({\n",
    "# #     '1d-direction': 'direction',\n",
    "#     'high52': 'highfiftytwo',\n",
    "#     'low52': 'lowfiftytwo',\n",
    "#     'vol1DayAvg': 'volonedayavg',\n",
    "#     'vol10DayAvg': 'voltendayavg',\n",
    "#     'vol3MonthAvg': 'volthreemonthavg'},\n",
    "#     axis=1,\n",
    "#     inplace=True)\n",
    "\n",
    "df_final.columns = df_final.columns.map(lambda row: \"_\".join(row.lower().split(\" \")))\n",
    "# df_final = df_final.loc[:, 'direction':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4eeca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs and outputs into model\n",
    "\n",
    "X = df_final.drop(['direction','stock','bearish','neutral','bullish','date','closing_price',\n",
    " 'highest_price','opeing_price','return'], axis=1)\n",
    "y = df_final['direction']\n",
    "\n",
    "X\n",
    "y\n",
    "\n",
    "# assert int(len(X.columns) +1) == len(df_final.columns)\n",
    "\n",
    "#df_final_temp = df_final.loc[:, 'direction':]\n",
    "# df_final_temp\n",
    "# df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f018bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to encode columns containing categorical data in X\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def encode_cats(categoricals, numericals, df):\n",
    "    \"\"\"\n",
    "    Takes in a list of categorical columns and a list of numerical columns and returns the dataframe with encoded variables\n",
    "    \"\"\"\n",
    "    ohe = OneHotEncoder(sparse=False, drop='first')\n",
    "    cat_matrix = ohe.fit_transform(df.loc[:, categoricals])\n",
    "    X_ohe = pd.DataFrame(cat_matrix,\n",
    "                         columns=ohe.get_feature_names(categoricals), #create meaningful column names\n",
    "                         index=X.index) #keep the same index values\n",
    "    \n",
    "    return pd.concat([X.loc[:, numericals], X_ohe], axis=1),ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1453a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the above function.\n",
    "\n",
    "categoricals = list(X.select_dtypes('object').columns)\n",
    "numericals = list(X.select_dtypes(['int64', 'float64', 'int32', 'float32']).columns)\n",
    "return_tupple = encode_cats(categoricals, numericals, X)\n",
    "X = return_tupple[0]\n",
    "ohe = return_tupple[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790377e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "(list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34626ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual predicting\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import auc, roc_auc_score, plot_roc_curve, confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve, PrecisionRecallDisplay, plot_confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58549b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42) #hold out 20% of the data for final testing\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81034614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_scaled,y_train)\n",
    "knn_scores = cross_val_score(knn, X_train_scaled, y_train, cv=5)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_scores = cross_val_score(rf, X_train_scaled, y_train, cv=5)\n",
    "\n",
    "print(f\"KNN mean scores: {np.mean(knn_scores):.4}\")\n",
    "print(f\"Random Forest mean scores: {np.mean(rf_scores):.4}\")\n",
    "\n",
    "len(list(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beccf456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickling/\"saving\" stuff\n",
    "import pickle\n",
    "\n",
    "myVar = {\"model\": rf, \"encoder\": ohe}\n",
    "\n",
    "with open('saved_steps.pkl','wb') as file:\n",
    "    pickle.dump(myVar,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5fcc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_today = pd.read_csv('2022-02-01-2022-02-01.csv')\n",
    "df_today\n",
    "\n",
    "stock_list_today = list(df_today['stock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8620b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "####THIS IS THE GET FUNDAMENTAL DATA STUFFF for now(START)\n",
    "\n",
    "def getFundamental(df,stock_list):\n",
    "    #Basically get each of the fundamental data points. Concat it\n",
    "\n",
    "    endpoint_fundamentals = r'https://api.tdameritrade.com/v1/instruments'\n",
    "\n",
    "    #Defining the payload\n",
    "\n",
    "    payload_fundamental = {'apikey': '4JHA7B4AE8VS1DQDUGATGHZPQIZNODEO',\n",
    "                            'symbol': stock_list,\n",
    "                          'projection':'fundamental'\n",
    "                          } #We need the tickers seperated by commas.\n",
    "\n",
    "\n",
    "    fundamental_content = requests.get(url = endpoint_fundamentals, params=payload_fundamental).json()\n",
    "\n",
    "\n",
    "    fund_cols = []\n",
    "    for column in [x for x in [*fundamental_content[stock_list[0]]['fundamental']]]:\n",
    "        fund_cols.append(column)\n",
    "\n",
    "    # Append data to dataframe\n",
    "    df_fundamental = pd.DataFrame(columns = fund_cols)\n",
    "    for stock in stock_list:\n",
    "        print(stock)\n",
    "        df_fundamental = df_fundamental.append(pd.Series(fundamental_content[stock]['fundamental'], index=fund_cols), ignore_index=True)\n",
    "\n",
    "\n",
    "    df_merged = pd.concat([df,df_fundamental], axis=1)\n",
    "    \n",
    "\n",
    "    #Removing unecessary columns\n",
    "    df_merged = df_merged.loc[:, ~df_merged.columns.duplicated()]\n",
    "    df_merged = df_merged[['stock',\n",
    "    'Bearish', 'Neutral', 'Bullish', 'Total_Compound', 'Date',\n",
    "    'high52',\n",
    "    'low52',\n",
    "    'returnOnEquity',\n",
    "    'returnOnAssets',\n",
    "    'totalDebtToCapital',\n",
    "    'totalDebtToEquity', 'vol10DayAvg',\n",
    "    'pegRatio','marketCap','dividendYield','epsTTM']]\n",
    "\n",
    "    df_merged.drop(df_merged.index[(((df_merged['Date'] //86400)+4)%7)==6], inplace=True) ##GETTING RID OF SATURDAYS\n",
    "    df_merged=df_merged.reset_index()\n",
    "\n",
    "    \n",
    "    #Remove duplicated columns\n",
    "    df_merged = df_merged.loc[:,~df_merged.columns.duplicated()]\n",
    "    #df_merged = df_merged.drop(['stock','bearish','neutral','bullish'], axis=1)\n",
    "    df_merged=df_merged.drop('stock', axis=1)\n",
    "    df_merged=df_merged.drop('Bearish', axis=1)\n",
    "    df_merged=df_merged.drop('Neutral', axis=1)\n",
    "    df_merged=df_merged.drop('Bullish', axis=1)\n",
    "\n",
    "    \n",
    "    return df_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df918a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = getFundamental(df_today, stock_list_today)\n",
    "\n",
    "len(list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468bd1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=knn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14d51d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
